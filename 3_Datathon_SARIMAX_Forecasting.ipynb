{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This code applies SARIMAX models found for each stock item to forecast sales for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libararies\n",
    "# importamos las librerias necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# check for incorrect data chaining\n",
    "pd.options.mode.chained_assignment = 'raise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data sets\n",
    "# importamos los datos  \n",
    "data_train = pd.read_csv('Modelar_UH2021.txt', sep='|', low_memory=False)\n",
    "data_test = pd.read_csv('Estimar_UH2021.txt', sep='|', low_memory=False)\n",
    "\n",
    "# select columns needed for further time series modelling\n",
    "# seleccionamos los campos que vamos a necesitar para el modelado de series temporales\n",
    "data = data_train.loc[:,['fecha','id','dia_atipico','campaña','unidades_vendidas']]\n",
    "data_t = data_test.loc[:,['fecha','id','dia_atipico','campaña']]\n",
    "\n",
    "# eliminate duplicates\n",
    "# eliminamos duplicados\n",
    "data = data.drop_duplicates()\n",
    "data_t = data_t.drop_duplicates()\n",
    "\n",
    "# change dates data type to 'timestamps' \n",
    "# cambiamos formato de las fechas a \"timestamp\"\n",
    "data['fecha']=pd.to_datetime(data['fecha'], format=\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique stock codes in the test dataset\n",
    "# los articulos en el conjunto de test\n",
    "codes_test = data_test['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting time series for individual stock code\n",
    "def get_ts (stock_code):\n",
    "\n",
    "    # read previously saved data for an individual stock code\n",
    "    path = './files/' +str(stock_code)+'.csv'   \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # read data for the stock code in the test set\n",
    "    df_t = data_t[data_t['id']==stock_code].copy()\n",
    "    \n",
    "    \n",
    "    # create time series dataframes for the stock code\n",
    "    df_ = pd.DataFrame(index=pd.date_range('2015-06-01', periods=488, freq='D'))\n",
    "    df_t_ = pd.DataFrame(index=pd.date_range('2016-10-01', periods=92, freq='D'))\n",
    "\n",
    "    # mark duplicates to eliminate\n",
    "    df.loc[:,'delete']=0\n",
    "    df_t.loc[:,'delete']=0\n",
    "    \n",
    "    fechas_dup = pd.Series(df['fecha'])[pd.Series(df['fecha']).duplicated()].values\n",
    "    for fecha in fechas_dup:\n",
    "        index = df[(df['fecha'] ==fecha ) & (df['campaña']==0)].index\n",
    "        df.loc[index, 'delete']=1\n",
    "\n",
    "    fechas_dup_t = pd.Series(df_t['fecha'])[pd.Series(df_t['fecha']).duplicated()].values\n",
    "    for fecha in fechas_dup_t:\n",
    "            index = df_t[(df_t['fecha'] ==fecha ) & (df_t['campaña']==0)].index\n",
    "            df_t.loc[index, 'delete']=1\n",
    "\n",
    "    # eliminate duplicates\n",
    "    index_names = df[df['delete'] == 1 ].index \n",
    "    df.drop(index_names, inplace = True)\n",
    "    \n",
    "    index_names = df_t[df_t['delete'] == 1 ].index \n",
    "    df_t.drop(index_names, inplace = True)\n",
    "\n",
    "    # change index to timestamp\n",
    "    df.index=df.loc[:,'fecha']\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df_t.index=df_t.loc[:,'fecha']\n",
    "    df_t.index = pd.to_datetime(df_t.index)    \n",
    "\n",
    "    # for each day of promotion ('campaña'=1), change'dia_atipico' to zero to have these codes independent \n",
    "    for i in range(len(df)):\n",
    "        if (df.loc[df.index[i],'campaña']==1):\n",
    "            df.loc[df.index[i],['dia_atipico']]=0   \n",
    "\n",
    "    for i in range(len(df_t)):\n",
    "        if (df_t.loc[df_t.index[i],'campaña']==1):\n",
    "            df_t.loc[df_t.index[i],['dia_atipico']]=0     \n",
    "          \n",
    "            \n",
    "    # eliminate columns which are no longer required\n",
    "    df = pd.DataFrame(df[['unidades_vendidas','campaña','dia_atipico']])\n",
    "    df_t = pd.DataFrame(df_t[['campaña','dia_atipico']])\n",
    "\n",
    "    # add time series to their dataframes, fill in the gaps with zeroes\n",
    "    ts = pd.concat([df_,df], axis=1)\n",
    "    ts = ts.fillna(value=0)\n",
    "    \n",
    "    ts_t = pd.concat([df_t_,df_t], axis=1)\n",
    "    ts_t = ts_t.fillna(value=0)\n",
    "    \n",
    "    # limit time series to the last year of observations\n",
    "    ts=ts.iloc[-365:,:]\n",
    "\n",
    "    return (ts, ts_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for forecasting\n",
    "def forecast (stock_code, ts_train, ts_test, order, seasonal_order):\n",
    "\n",
    "    # fit the model using labeled time series\n",
    "    model = SARIMAX(ts_train['unidades_vendidas'], exog=ts_train[['campaña', 'dia_atipico']],\n",
    "                    order=order, seasonal_order = seasonal_order).fit()\n",
    "    \n",
    "    # make predictions for test time series\n",
    "    start=len(ts_train)\n",
    "    end=len(ts_train)+len(ts_test)-1\n",
    "    predictions = model.predict(start=start, end=end, exog=ts_test[['campaña', 'dia_atipico']])\n",
    "    \n",
    "    \n",
    "    # change negative forecast values to zero\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] < 0:\n",
    "            predictions[i] = 0\n",
    "    \n",
    "   \n",
    "    # add predicted values to dataframe\n",
    "    df_pred = pd.DataFrame(index=ts_test.index)\n",
    "    df_pred.loc[:,'id']=stock_code\n",
    "    df_pred.loc[:,'unidades_vendidas'] = predictions.to_list()\n",
    "    \n",
    "    return (df_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parameters of models found previously\n",
    "# importamos los parametros de modelos encontrados previamente\n",
    "parameters =  pd.read_csv('sarima_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with parameters\n",
    "params ={}\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    id = parameters.iloc[i,0]\n",
    "    order = parameters.iloc[i,1]\n",
    "    seasonal_order = parameters.iloc[i,2]\n",
    "    params[id]=[order, seasonal_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe for predictions\n",
    "# hacemos dataframe para predicciones\n",
    "sarima_pred = pd.DataFrame(columns=['id','unidades_vendidas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in codes_test:\n",
    "\n",
    "    # read model parameters for stock code\n",
    "    order = eval(params[each][0])\n",
    "    seasonal_order = eval(params[each][1])\n",
    "    \n",
    "    # get train and test timeseries for the stock code\n",
    "    ts, ts_t = get_ts(each)\n",
    "\n",
    "    # get forecast for the stock code\n",
    "    forecast_df = forecast(each, ts, ts_t, order, seasonal_order)\n",
    "\n",
    "    # add forecast to dataframe \n",
    "    sarima_pred = pd.concat([sarima_pred, forecast_df])\n",
    "\n",
    "    # print progress line\n",
    "    print('Item number: '+str(len(sarima_pred)) + ', Item code: '+ str(each))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a file\n",
    "# guardamos dataframe como archivo\n",
    "sarima_pred.to_csv('sarima_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This code produces SARIMAX models for each stock item in the test set, makes predictions for a validation period and calculates predictions errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libararies\n",
    "# importamos las librerias necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "pd.options.mode.chained_assignment = 'raise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data sets\n",
    "# importamos los datos  \n",
    "data_train = pd.read_csv('Modelar_UH2021.txt', sep='|', low_memory=False)\n",
    "data_test = pd.read_csv('Estimar_UH2021.txt', sep='|', low_memory=False)\n",
    "\n",
    "# select columns needed for further time series modelling\n",
    "# seleccionamos los campos que vamos a necesitar para el modelado de series temporales\n",
    "data = data_train.loc[:,['fecha','id','dia_atipico','campaña','unidades_vendidas']]\n",
    "\n",
    "\n",
    "# eliminate duplicates\n",
    "# eliminamos duplicados\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# change dates data type to 'timestamps' \n",
    "# cambiamos formato de las fechas a \"timestamp\"\n",
    "data['fecha']=pd.to_datetime(data['fecha'], format=\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique stock codes in the test dataset\n",
    "# los articulos en el conjunto de test\n",
    "codes_test = data_test['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save separate files for each stock code to be predicted\n",
    "# creamos y guardamos los archivos separados para los articulos que debemos pronosticar\n",
    "for each in codes_test:\n",
    "    df = data[data['id']==each].copy()\n",
    "    path = './files/' +str(each)+'.csv'\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for data preprocessing\n",
    "def prep_data (stock_code):\n",
    "    \n",
    "    # read previously saved file for an individual stock code\n",
    "    path = './files/' +str(each)+'.csv'   \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # create dataframe for the stock code's time series\n",
    "    df_ = pd.DataFrame(index=pd.date_range('2015-06-01', periods=488, freq='D'))\n",
    "\n",
    "    # mark duplcates to eliminate\n",
    "    df.loc[:,'delete']=0\n",
    "        \n",
    "    fechas_dup = pd.Series(df['fecha'])[pd.Series(df['fecha']).duplicated()].values\n",
    "    for fecha in fechas_dup:\n",
    "        index = df[(df['fecha'] ==fecha ) & (df['campaña']==0)].index\n",
    "        df.loc[index, 'delete']=1\n",
    "    \n",
    "    # eliminate duplicates\n",
    "    index_names = df[df['delete'] == 1 ].index \n",
    "    df.drop(index_names, inplace = True)\n",
    "    \n",
    "    # change the index\n",
    "    df.index=df.loc[:,'fecha']\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # for each day of promotion ('campaña'=1), change 'dia_atipico' to zero to have these codes independent \n",
    "    for i in range(len(df)):\n",
    "        if (df.loc[df.index[i],'campaña']==1):\n",
    "            df.loc[df.index[i],['dia_atipico']]=0   \n",
    "\n",
    "    # eliminate the columns which are not longer required\n",
    "    df = pd.DataFrame(df[['unidades_vendidas', 'visitas','campaña','dia_atipico']])\n",
    "\n",
    "    # add time series to its dataframe, fill in the gaps with zeroes\n",
    "    ts = pd.concat([df_,df], axis=1)\n",
    "    ts = ts.fillna(value=0)\n",
    "    \n",
    "    # limit the series to the last year of observations\n",
    "    ts=ts.iloc[-365:,:]\n",
    "\n",
    "    return(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for modeling with SARIMAX\n",
    "def modeling (ts):\n",
    "\n",
    "    # divide data in train and validation sets\n",
    "    train = ts.iloc[:-90,:]\n",
    "    test = ts.iloc[-90:,:]\n",
    "\n",
    "    # look for best model for the series with 'autoarima'\n",
    "    res = auto_arima(ts['unidades_vendidas'], exogenous=ts[['campaña', 'dia_atipico']], m=7,\n",
    "                     suppress_warnings=True, enforce_invertibility=False)\n",
    "    \n",
    "    order = res.order\n",
    "    seasonal_order = res.seasonal_order\n",
    "    \n",
    "    \n",
    "    # fit the model using train set\n",
    "    model = SARIMAX(train['unidades_vendidas'], exog=train[['visitas','campaña', 'dia_atipico']],\n",
    "                    order=order,\n",
    "                    seasonal_order = seasonal_order).fit()\n",
    "    \n",
    "    # make predictions for validation set\n",
    "    start=len(train)\n",
    "    end=len(train)+len(test)-1\n",
    "    predictions = model.predict(start=start, end=end, exog=test[['visitas','campaña', 'dia_atipico']])\n",
    "    \n",
    "    \n",
    "    # change negative values to zero\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] < 0:\n",
    "            predictions[i] = 0\n",
    "    \n",
    "    # calculate prediction error\n",
    "    mae = mean_absolute_error(test['unidades_vendidas'], predictions)\n",
    "    \n",
    "    # calculate proportion MAE/STD\n",
    "    coef = mae / (test['unidades_vendidas'].std()+0.001)\n",
    "    \n",
    "    return ([order, seasonal_order, mae, coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a dictionary for keeping the modeling results\n",
    "# El diccionario para guardar los resultados del modelado\n",
    "results_sarima = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DONT FORGET TO CHANGE!! missing_codes -> codes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "898"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DONT FORGET TO FELETE\n",
    "parameters =  pd.read_csv('sarima_models.csv')\n",
    "codes = parameters['id'].to_list()\n",
    "missing_codes = []\n",
    "for each in codes_test:\n",
    "    if each not in codes:\n",
    "        missing_codes.append(each)\n",
    "len(missing_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:975: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:994: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1006: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item number: 842, Item code: 431976, MAE: 6.094059917447479, Coef: 0.712876134999981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:975: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:994: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1006: UserWarning: Non-invertible starting seasonal moving average Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting seasonal moving average'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item number: 843, Item code: 432100, MAE: 78.59300904036493, Coef: 3.7687958334233476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:963: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:994: UserWarning: Non-stationary starting seasonal autoregressive Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting seasonal autoregressive'\n",
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item number: 844, Item code: 432116, MAE: 6.922006288386363, Coef: 0.7063030288041544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanya\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:963: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Non-positive-definite forecast error covariance matrix encountered at period 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mstatsmodels/tsa/statespace/_filters/_inversions.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa.statespace._filters._inversions.dinverse_univariate\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-8357cd3d2909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mresults_sarima\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_sarima\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mresults_sarima\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meach\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-cc466bef1cd2>\u001b[0m in \u001b[0;36mmodeling\u001b[1;34m(ts)\u001b[0m\n\u001b[0;32m     17\u001b[0m     model = SARIMAX(train['unidades_vendidas'], exog=train[['visitas','campaña', 'dia_atipico']],\n\u001b[0;32m     18\u001b[0m                     \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     seasonal_order = seasonal_order).fit()\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# make predictions for validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m                                                \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m                                                \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                                                skip_hessian=True, **kwargs)\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;31m# Just return the fitted parameters if requested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                                        \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                                                        \u001b[0mretall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                                                        full_output=full_output)\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# NOTE: this is for fit_regularized and should be generalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    216\u001b[0m                             \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                             \u001b[0mretall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                             hess=hessian)\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         optim_settings = {'optimizer': method, 'start_params': start_params,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    438\u001b[0m                                      \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                                      \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                                      **extra_kwargs)\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\u001b[0m in \u001b[0;36mloglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inversion_method'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mINVERT_UNIVARIATE\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mSOLVE_LU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mloglike\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[1;31m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\u001b[0m in \u001b[0;36mloglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m         kwargs.setdefault('conserve_memory',\n\u001b[0;32m    976\u001b[0m                           MEMORY_CONSERVE ^ MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m--> 977\u001b[1;33m         \u001b[0mkfilter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m         loglikelihood_burn = kwargs.get('loglikelihood_burn',\n\u001b[0;32m    979\u001b[0m                                         self.loglikelihood_burn)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py\u001b[0m in \u001b[0;36m_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[1;31m# Run the filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m         \u001b[0mkfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkfilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstatsmodels/tsa/statespace/_kalman_filter.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mstatsmodels/tsa/statespace/_kalman_filter.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__next__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mstatsmodels/tsa/statespace/_filters/_inversions.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa.statespace._filters._inversions.dinverse_univariate\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Non-positive-definite forecast error covariance matrix encountered at period 1"
     ]
    }
   ],
   "source": [
    "# complete dictionary with found models' parameters for all stock codes\n",
    "# TIME CONSUMING!\n",
    "for each in missing_codes[847:]:#codes_test:\n",
    "    \n",
    "    ts = prep_data(each)\n",
    "    results_sarima[each] = modeling(ts)\n",
    "    mae = results_sarima[each][2]\n",
    "    coef =results_sarima[each][3]\n",
    "    \n",
    "    # print the progress line\n",
    "    print('Item number: '+str(len(results_sarima)) + ', Item code: '+ str(each)+ ', MAE: '+str(mae)+', Coef: '+ str(coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431972"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_codes[746]\n",
    "missing_codes[782]\n",
    "missing_codes[827]\n",
    "missing_codes[834]\n",
    "missing_codes[845]\n",
    "missing_codes[846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to a dataframe\n",
    "# guardamos los resultados en dataframe\n",
    "sarima_res=pd.DataFrame(columns=['id','order','seasonal_order','mae','coef'])\n",
    "\n",
    "id=[]\n",
    "order=[]\n",
    "seasonal_order=[]\n",
    "mae=[]\n",
    "coef=[]\n",
    "\n",
    "for each in results_sarima:\n",
    "    id.append(each)\n",
    "    order.append(results_sarima[each][0])\n",
    "    seasonal_order.append(results_sarima[each][1])\n",
    "    mae.append(results_sarima[each][2])\n",
    "    coef.append(results_sarima[each][3])\n",
    "    \n",
    "sarima_res['id']=id\n",
    "sarima_res['order']=order\n",
    "sarima_res['seasonal_order']=seasonal_order\n",
    "sarima_res['mae']=mae\n",
    "sarima_res['coef']=coef\n",
    "\n",
    "# save the dataframe as a file\n",
    "# guardamos dataframe como archivo\n",
    "sarima_res.to_csv('sarima_res_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sarima_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
